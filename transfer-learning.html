<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>transfer-learning</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Convolutional-Neural-Networks">Convolutional Neural Networks<a class="anchor-link" href="#Convolutional-Neural-Networks">&#182;</a></h1><h2 id="Project:-Write-an-Algorithm-for-Landmark-Classification">Project: Write an Algorithm for Landmark Classification<a class="anchor-link" href="#Project:-Write-an-Algorithm-for-Landmark-Classification">&#182;</a></h2><h3 id="Transfer-learning">Transfer learning<a class="anchor-link" href="#Transfer-learning">&#182;</a></h3><p>In the previous notebook we have trained our own CNN and we got a certain performance. Let's see how hard it is to match that performance with transfer learning.</p>
<hr>
<h2 id="-Step-0:-Setting-up"><img alt="&gt;" src="https://github.com/nathanbangwa243/udpj-landmark-classification/blob/main/static_images/icons/noun-advance-2109145.png?raw=1" style="width:50px" /> Step 0: Setting up<a class="anchor-link" href="#-Step-0:-Setting-up">&#182;</a></h2><p>The following cells make sure that your environment is setup correctly and check that your GPU is available and ready to go. You have to execute them every time you restart your notebook.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TRAINING-PLATFORM">TRAINING PLATFORM<a class="anchor-link" href="#TRAINING-PLATFORM">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">TRAINING_PLATFORM</span> <span class="o">=</span> <span class="s2">&quot;KAGGLE&quot;</span> <span class="c1"># replace by UDACITY</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="n">TRAINING_PLATFORM</span> <span class="o">==</span> <span class="s2">&quot;GOOGLE&quot;</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
    <span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive/&#39;</span><span class="p">)</span>

    <span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s2">&quot;/content/drive/MyDrive/learning/udacity/ml-fundamentals/udpj-landmark-classification&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="KAGGLE-SETUP">KAGGLE SETUP<a class="anchor-link" href="#KAGGLE-SETUP">&#182;</a></h3><p>Remember to turn ON internet for download purpose : <code>Settings Tab &gt; Turn ON internet</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="n">TRAINING_PLATFORM</span> <span class="o">==</span> <span class="s2">&quot;KAGGLE&quot;</span><span class="p">:</span>

    <span class="c1"># Rpertoires source et destination</span>
    <span class="n">source_dir</span> <span class="o">=</span> <span class="s1">&#39;/kaggle/input/udpj-starter-code/udpj-landmark-classification/&#39;</span>
    <span class="n">destination_dir</span> <span class="o">=</span> <span class="s1">&#39;/kaggle/working/&#39;</span>

    <span class="c1"># Copier tous les fichiers et dossiers de la source vers la destination</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">copytree</span><span class="p">(</span><span class="n">source_dir</span><span class="p">,</span> <span class="n">destination_dir</span><span class="p">,</span> <span class="n">dirs_exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="COMMON-SETUP">COMMON SETUP<a class="anchor-link" href="#COMMON-SETUP">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pwd
<span class="o">!</span>ls
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>/kaggle/working
README.md		 mean_and_std.pt	   static_images
app.ipynb		 requirements.txt	   transfer_learning.ipynb
cnn_from_scratch.ipynb	 reverse_requirements.txt
install_requirements.sh  src
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>apt install build-essential
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Reading package lists... Done
Building dependency tree       
Reading state information... Done
build-essential is already the newest version (12.8ubuntu1.1).
0 upgraded, 0 newly installed, 0 to remove and 80 not upgraded.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>cat requirements.txt
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>opencv-python-headless==4.5.3.56
matplotlib==3.4.3
numpy==1.21.2
pillow==7.0.0
bokeh==2.1.1
torch==1.9.0
torchvision==0.10.0
tqdm==4.63.0
ipywidgets==7.6.5
livelossplot==0.5.4
pytest==7.1.1
pandas==1.3.5
seaborn==0.11.2
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install --upgrade pip setuptools wheel
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (24.2)
Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (72.1.0)
Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (0.44.0)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip cache purge
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Files removed: 12
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Install requirements</span>
<span class="o">!</span>pip install -r requirements.txt <span class="p">|</span> grep -v <span class="s2">&quot;already satisfied&quot;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting opencv-python-headless==4.5.3.56 (from -r requirements.txt (line 1))
  Downloading opencv-python-headless-4.5.3.56.tar.gz (89.2 MB)
     <span class="ansi-black-intense-fg"></span> <span class="ansi-green-fg">89.2/89.2 MB</span> <span class="ansi-red-fg">61.5 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>00:0100:01
  Installing build dependencies: started
  Installing build dependencies: still running...
  Installing build dependencies: finished with status &#39;error&#39;
  <span class="ansi-red-intense-fg ansi-bold">error</span>: <span class="ansi-bold">subprocess-exited-with-error</span>
  
  <span class="ansi-red-fg"></span> <span class="ansi-green-fg">pip subprocess to install build dependencies</span> did not run successfully.
  <span class="ansi-red-fg"></span> exit code: <span class="ansi-cyan-intense-fg ansi-bold">1</span>
  <span class="ansi-red-fg">&gt;</span> <span class="ansi-red-fg">[851 lines of output]</span>
  <span class="ansi-red-fg">   </span> Ignoring numpy: markers &#39;python_version == &#34;3.6&#34; and platform_machine != &#34;aarch64&#34; and platform_machine != &#34;arm64&#34;&#39; don&#39;t match your environment
  <span class="ansi-red-fg">   </span> Ignoring numpy: markers &#39;python_version &gt;= &#34;3.6&#34; and sys_platform == &#34;linux&#34; and platform_machine == &#34;aarch64&#34;&#39; don&#39;t match your environment
  <span class="ansi-red-fg">   </span> Ignoring numpy: markers &#39;python_version &gt;= &#34;3.6&#34; and sys_platform == &#34;darwin&#34; and platform_machine == &#34;arm64&#34;&#39; don&#39;t match your environment
  <span class="ansi-red-fg">   </span> Ignoring numpy: markers &#39;python_version == &#34;3.7&#34; and platform_machine != &#34;aarch64&#34; and platform_machine != &#34;arm64&#34;&#39; don&#39;t match your environment
  <span class="ansi-red-fg">   </span> Ignoring numpy: markers &#39;python_version == &#34;3.8&#34; and platform_machine != &#34;aarch64&#34; and platform_machine != &#34;arm64&#34;&#39; don&#39;t match your environment
  <span class="ansi-red-fg">   </span> Collecting setuptools
  <span class="ansi-red-fg">   </span>   Downloading setuptools-72.1.0-py3-none-any.whl.metadata (6.6 kB)
  <span class="ansi-red-fg">   </span> Collecting wheel
  <span class="ansi-red-fg">   </span>   Downloading wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)
  <span class="ansi-red-fg">   </span> Collecting scikit-build
  <span class="ansi-red-fg">   </span>   Downloading scikit_build-0.18.0-py3-none-any.whl.metadata (17 kB)
  <span class="ansi-red-fg">   </span> Collecting cmake
  <span class="ansi-red-fg">   </span>   Downloading cmake-3.30.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)
  <span class="ansi-red-fg">   </span> Collecting pip
  <span class="ansi-red-fg">   </span>   Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)
  <span class="ansi-red-fg">   </span> Collecting numpy==1.19.3
  <span class="ansi-red-fg">   </span>   Downloading numpy-1.19.3.zip (7.3 MB)
  <span class="ansi-red-fg">   </span>      <span class="ansi-black-intense-fg"></span> <span class="ansi-green-fg">0.0/7.3 MB</span> <span class="ansi-red-fg">?</span> eta <span class="ansi-cyan-fg">-:--:--</span>
  <span class="ansi-red-fg">   </span>      <span class="ansi-red-intense-fg"></span><span class="ansi-red-intense-fg"></span><span class="ansi-black-intense-fg"></span> <span class="ansi-green-fg">3.4/7.3 MB</span> <span class="ansi-red-fg">26.2 MB/s</span> eta <span class="ansi-cyan-fg">0:00:01</span>
  <span class="ansi-red-fg">   </span>      <span class="ansi-black-intense-fg"></span> <span class="ansi-green-fg">7.3/7.3 MB</span> <span class="ansi-red-fg">36.7 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
  <span class="ansi-red-fg">   </span>   Installing build dependencies: started
  <span class="ansi-red-fg">   </span>   Installing build dependencies: finished with status &#39;done&#39;
  <span class="ansi-red-fg">   </span>   Getting requirements to build wheel: started
  <span class="ansi-red-fg">   </span>   Getting requirements to build wheel: finished with status &#39;done&#39;
  <span class="ansi-red-fg">   </span>   Preparing metadata (pyproject.toml): started
  <span class="ansi-red-fg">   </span>   Preparing metadata (pyproject.toml): finished with status &#39;done&#39;
  <span class="ansi-red-fg">   </span> Collecting distro (from scikit-build)
  <span class="ansi-red-fg">   </span>   Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)
  <span class="ansi-red-fg">   </span> Collecting packaging (from scikit-build)
  <span class="ansi-red-fg">   </span>   Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)
  <span class="ansi-red-fg">   </span> Collecting tomli (from scikit-build)
  <span class="ansi-red-fg">   </span>   Downloading tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)
  <span class="ansi-red-fg">   </span> Downloading setuptools-72.1.0-py3-none-any.whl (2.3 MB)
  <span class="ansi-red-fg">   </span>    <span class="ansi-black-intense-fg"></span> <span class="ansi-green-fg">0.0/2.3 MB</span> <span class="ansi-red-fg">?</span> eta <span class="ansi-cyan-fg">-:--:--</span>
  <span class="ansi-red-fg">   </span>    <span class="ansi-black-intense-fg"></span> <span class="ansi-green-fg">2.3/2.3 MB</span> <span class="ansi-red-fg">75.8 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
  <span class="ansi-red-fg">   </span> Downloading wheel-0.44.0-py3-none-any.whl (67 kB)
  <span class="ansi-red-fg">   </span> Downloading scikit_build-0.18.0-py3-none-any.whl (85 kB)
  <span class="ansi-red-fg">   </span> Downloading cmake-3.30.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.9 MB)
  <span class="ansi-red-fg">   </span>    <span class="ansi-black-intense-fg"></span> <span class="ansi-green-fg">0.0/26.9 MB</span> <span class="ansi-red-fg">?</span> eta <span class="ansi-cyan-fg">-:--:--</span>
  <span class="ansi-red-fg">   </span>    <span class="ansi-red-intense-fg"></span><span class="ansi-black-intense-fg"></span><span class="ansi-black-intense-fg"></span> <span class="ansi-green-fg">19.7/26.9 MB</span> <span class="ansi-red-fg">105.9 MB/s</span> eta <span class="ansi-cyan-fg">0:00:01</span>
  <span class="ansi-red-fg">   </span>    <span class="ansi-black-intense-fg"></span> <span class="ansi-green-fg">26.9/26.9 MB</span> <span class="ansi-red-fg">69.9 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
  <span class="ansi-red-fg">   </span> Downloading pip-24.2-py3-none-any.whl (1.8 MB)
  <span class="ansi-red-fg">   </span>    <span class="ansi-black-intense-fg"></span> <span class="ansi-green-fg">0.0/1.8 MB</span> <span class="ansi-red-fg">?</span> eta <span class="ansi-cyan-fg">-:--:--</span>
  <span class="ansi-red-fg">   </span>    <span class="ansi-black-intense-fg"></span> <span class="ansi-green-fg">1.8/1.8 MB</span> <span class="ansi-red-fg">55.2 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
  <span class="ansi-red-fg">   </span> Downloading distro-1.9.0-py3-none-any.whl (20 kB)
  <span class="ansi-red-fg">   </span> Downloading packaging-24.1-py3-none-any.whl (53 kB)
  <span class="ansi-red-fg">   </span> Downloading tomli-2.0.1-py3-none-any.whl (12 kB)
  <span class="ansi-red-fg">   </span> Building wheels for collected packages: numpy
  <span class="ansi-red-fg">   </span>   Building wheel for numpy (pyproject.toml): started
  <span class="ansi-red-fg">   </span>   Building wheel for numpy (pyproject.toml): finished with status &#39;error&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-intense-fg ansi-bold">error</span>: <span class="ansi-bold">subprocess-exited-with-error</span>
  <span class="ansi-red-fg">   </span> 
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg"></span> <span class="ansi-green-fg">Building wheel for numpy </span><span class="ansi-green-intense-fg ansi-bold">(</span><span class="ansi-green-fg">pyproject.toml</span><span class="ansi-green-intense-fg ansi-bold">)</span> did not run successfully.
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg"></span> exit code: <span class="ansi-cyan-intense-fg ansi-bold">1</span>
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">&gt;</span> <span class="ansi-red-fg">[789 lines of output]</span>
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> setup.py:67: RuntimeWarning: NumPy 1.19.3 may not yet support Python 3.10.
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>   warnings.warn(
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Running from numpy source directory.
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/random/_bounded_integers.pxd.in has not changed
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/random/_pcg64.pyx has not changed
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Processing numpy/random/_bounded_integers.pyx
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/random/_generator.pyx has not changed
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/random/_philox.pyx has not changed
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/random/_bounded_integers.pyx.in has not changed
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/random/bit_generator.pyx has not changed
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/random/_sfc64.pyx has not changed
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/random/_mt19937.pyx has not changed
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/random/mtrand.pyx has not changed
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/random/_common.pyx has not changed
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Cythonizing sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> blas_opt_info:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> blas_mkl_info:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> customize UnixCCompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>   FOUND:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     libraries = [&#39;mkl_rt&#39;, &#39;pthread&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     library_dirs = [&#39;/opt/conda/lib&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     define_macros = [(&#39;SCIPY_MKL_H&#39;, None), (&#39;HAVE_CBLAS&#39;, None)]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     include_dirs = [&#39;/usr/local/include&#39;, &#39;/usr/include&#39;, &#39;/opt/conda/include&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>   FOUND:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     libraries = [&#39;mkl_rt&#39;, &#39;pthread&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     library_dirs = [&#39;/opt/conda/lib&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     define_macros = [(&#39;SCIPY_MKL_H&#39;, None), (&#39;HAVE_CBLAS&#39;, None)]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     include_dirs = [&#39;/usr/local/include&#39;, &#39;/usr/include&#39;, &#39;/opt/conda/include&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> non-existing path in &#39;numpy/distutils&#39;: &#39;site.cfg&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> lapack_opt_info:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> lapack_mkl_info:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>   FOUND:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     libraries = [&#39;mkl_rt&#39;, &#39;pthread&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     library_dirs = [&#39;/opt/conda/lib&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     define_macros = [(&#39;SCIPY_MKL_H&#39;, None), (&#39;HAVE_CBLAS&#39;, None)]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     include_dirs = [&#39;/usr/local/include&#39;, &#39;/usr/include&#39;, &#39;/opt/conda/include&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>   FOUND:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     libraries = [&#39;mkl_rt&#39;, &#39;pthread&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     library_dirs = [&#39;/opt/conda/lib&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     define_macros = [(&#39;SCIPY_MKL_H&#39;, None), (&#39;HAVE_CBLAS&#39;, None)]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>     include_dirs = [&#39;/usr/local/include&#39;, &#39;/usr/include&#39;, &#39;/opt/conda/include&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /tmp/pip-build-env-ssoh16rv/overlay/lib/python3.10/site-packages/setuptools/_distutils/dist.py:275: UserWarning: Unknown distribution option: &#39;define_macros&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>   warnings.warn(msg)
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> running bdist_wheel
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> running build
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> running config_cc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> unifing config_cc, config, build_clib, build_ext, build commands --compiler options
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> running config_fc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> running build_src
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> build_src
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building py_modules sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building library &#34;npymath&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable gfortran
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable f95
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable ifort
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable ifc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable lf95
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable pgfortran
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable nvfortran
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable f90
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable f77
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable fort
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable efort
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable efc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable g77
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable g95
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable pathf95
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> Could not locate executable nagfor
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> don&#39;t know how to compile Fortran code on platform &#39;posix&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>   adding &#39;build/src.linux-x86_64-3.10/numpy/core/src/npymath&#39; to include_dirs.
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> None - nothing done with h_files = [&#39;build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_internal.h&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building library &#34;npysort&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>   adding &#39;build/src.linux-x86_64-3.10/numpy/core/src/common&#39; to include_dirs.
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> None - nothing done with h_files = [&#39;build/src.linux-x86_64-3.10/numpy/core/src/common/npy_sort.h&#39;, &#39;build/src.linux-x86_64-3.10/numpy/core/src/common/npy_partition.h&#39;, &#39;build/src.linux-x86_64-3.10/numpy/core/src/common/npy_binsearch.h&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building library &#34;npyrandom&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.core._multiarray_tests&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.core._multiarray_umath&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>   adding &#39;build/src.linux-x86_64-3.10/numpy/core/src/umath&#39; to include_dirs.
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>   adding &#39;build/src.linux-x86_64-3.10/numpy/core/src/npymath&#39; to include_dirs.
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>   adding &#39;build/src.linux-x86_64-3.10/numpy/core/src/common&#39; to include_dirs.
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy.core - nothing done with h_files = [&#39;build/src.linux-x86_64-3.10/numpy/core/src/umath/funcs.inc&#39;, &#39;build/src.linux-x86_64-3.10/numpy/core/src/umath/simd.inc&#39;, &#39;build/src.linux-x86_64-3.10/numpy/core/src/umath/loops.h&#39;, &#39;build/src.linux-x86_64-3.10/numpy/core/src/umath/matmul.h&#39;, &#39;build/src.linux-x86_64-3.10/numpy/core/src/umath/clip.h&#39;, &#39;build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_internal.h&#39;, &#39;build/src.linux-x86_64-3.10/numpy/core/src/common/templ_common.h&#39;, &#39;build/src.linux-x86_64-3.10/numpy/core/include/numpy/config.h&#39;, &#39;build/src.linux-x86_64-3.10/numpy/core/include/numpy/_numpyconfig.h&#39;, &#39;build/src.linux-x86_64-3.10/numpy/core/include/numpy/__multiarray_api.h&#39;, &#39;build/src.linux-x86_64-3.10/numpy/core/include/numpy/__ufunc_api.h&#39;]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.core._umath_tests&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.core._rational_tests&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.core._struct_ufunc_tests&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.core._operand_flag_tests&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.fft._pocketfft_internal&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.linalg.lapack_lite&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.linalg._umath_linalg&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.random._mt19937&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.random._philox&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.random._pcg64&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.random._sfc64&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.random._common&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.random.bit_generator&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.random._generator&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.random._bounded_integers&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building extension &#34;numpy.random.mtrand&#34; sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building data_files sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> build_src: building npy-pkg config files
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> running build_py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/_globals.py -&gt; build/lib.linux-x86_64-3.10/numpy
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ctypeslib.py -&gt; build/lib.linux-x86_64-3.10/numpy
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/version.py -&gt; build/lib.linux-x86_64-3.10/numpy
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/conftest.py -&gt; build/lib.linux-x86_64-3.10/numpy
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/dual.py -&gt; build/lib.linux-x86_64-3.10/numpy
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/_pytesttester.py -&gt; build/lib.linux-x86_64-3.10/numpy
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/matlib.py -&gt; build/lib.linux-x86_64-3.10/numpy
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/_distributor_init.py -&gt; build/lib.linux-x86_64-3.10/numpy
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/setup.py -&gt; build/lib.linux-x86_64-3.10/numpy
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying build/src.linux-x86_64-3.10/numpy/__config__.py -&gt; build/lib.linux-x86_64-3.10/numpy
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/compat
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/compat/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/compat
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/compat/py3k.py -&gt; build/lib.linux-x86_64-3.10/numpy/compat
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/compat/_inspect.py -&gt; build/lib.linux-x86_64-3.10/numpy/compat
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/compat/setup.py -&gt; build/lib.linux-x86_64-3.10/numpy/compat
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/compat/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/compat/tests/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/compat/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/compat/tests/test_compat.py -&gt; build/lib.linux-x86_64-3.10/numpy/compat/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/_exceptions.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/einsumfunc.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/getlimits.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/shape_base.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/_dtype.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/_add_newdocs.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/defchararray.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/fromnumeric.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/_asarray.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/numerictypes.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/arrayprint.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/_string_helpers.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/_dtype_ctypes.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/records.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/machar.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/_methods.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/_ufunc_config.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/overrides.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/umath_tests.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/memmap.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/function_base.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/setup_common.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/numeric.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/_internal.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/cversions.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/setup.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/multiarray.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/umath.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/_type_aliases.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/code_generators/generate_numpy_api.py -&gt; build/lib.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test__exceptions.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_extint128.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_indexing.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_indexerrors.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_unicode.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_scalarbuffer.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_protocols.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_scalar_ctors.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_regression.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_conversion_utils.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_numerictypes.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_shape_base.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_scalarprint.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_multiarray.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_longdouble.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_defchararray.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_overrides.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_item_selection.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_einsum.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_mem_overlap.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_scalar_methods.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_ufunc.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_print.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_function_base.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_half.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_datetime.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_numeric.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_cpu_features.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_scalarinherit.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_getlimits.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_deprecations.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_errstate.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/_locales.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_umath_complex.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_umath.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_arrayprint.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_dtype.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_abc.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_scalarmath.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_memmap.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_umath_accuracy.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_api.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_machar.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_records.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/core/tests/test_nditer.py -&gt; build/lib.linux-x86_64-3.10/numpy/core/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/misc_util.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/from_template.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/mingw32ccompiler.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/msvccompiler.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/system_info.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/numpy_distribution.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/exec_command.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/cpuinfo.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/npy_pkg_config.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/extension.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/log.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/ccompiler.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/_shell_utils.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/conv_template.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/line_endings.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/pathccompiler.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/intelccompiler.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/unixccompiler.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/msvc9compiler.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/lib2def.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/setup.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/core.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying build/src.linux-x86_64-3.10/numpy/distutils/__config__.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/build.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/install_headers.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/build_src.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/bdist_rpm.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/config_compiler.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/install_data.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/build_scripts.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/autodist.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/build_ext.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/sdist.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/install.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/config.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/build_clib.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/egg_info.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/install_clib.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/build_py.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/command/develop.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/command
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/intel.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/compaq.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/hpux.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/environment.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/nag.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/sun.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/ibm.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/mips.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/pathf95.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/g95.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/lahey.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/none.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/nv.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/vast.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/gnu.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/pg.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/fcompiler/absoft.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/distutils/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/tests/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/tests/test_exec_command.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/tests/test_fcompiler_nagfor.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/tests/test_fcompiler.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/tests/test_mingw32ccompiler.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/tests/test_system_info.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/tests/test_from_template.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/tests/test_misc_util.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/tests/test_fcompiler_gnu.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/tests/test_npy_pkg_config.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/tests/test_fcompiler_intel.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/distutils/tests/test_shell_utils.py -&gt; build/lib.linux-x86_64-3.10/numpy/distutils/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/doc/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/doc/subclassing.py -&gt; build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/doc/internals.py -&gt; build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/doc/dispatch.py -&gt; build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/doc/byteswapping.py -&gt; build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/doc/basics.py -&gt; build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/doc/structured_arrays.py -&gt; build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/doc/broadcasting.py -&gt; build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/doc/misc.py -&gt; build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/doc/creation.py -&gt; build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/doc/glossary.py -&gt; build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/doc/constants.py -&gt; build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/doc/ufuncs.py -&gt; build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/doc/indexing.py -&gt; build/lib.linux-x86_64-3.10/numpy/doc
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/common_rules.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/capi_maps.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/f2py2e.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/use_rules.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/rules.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/crackfortran.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/cb_rules.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/cfuncs.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/f90mod_rules.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/diagnose.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/f2py_testing.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/__main__.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/__version__.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/setup.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/auxfuncs.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/func2subr.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_compile_function.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_regression.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_kind.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_crackfortran.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_block_docstring.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_parameter.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_return_logical.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_array_from_pyobj.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_mixed.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_common.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_size.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_assumed_shape.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_return_real.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_return_character.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_return_integer.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_quoted_character.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_semicolon_split.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/util.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_return_complex.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_string.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/f2py/tests/test_callback.py -&gt; build/lib.linux-x86_64-3.10/numpy/f2py/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/fft
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/fft/helper.py -&gt; build/lib.linux-x86_64-3.10/numpy/fft
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/fft/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/fft
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/fft/_pocketfft.py -&gt; build/lib.linux-x86_64-3.10/numpy/fft
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/fft/setup.py -&gt; build/lib.linux-x86_64-3.10/numpy/fft
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/fft/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/fft/tests/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/fft/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/fft/tests/test_helper.py -&gt; build/lib.linux-x86_64-3.10/numpy/fft/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/fft/tests/test_pocketfft.py -&gt; build/lib.linux-x86_64-3.10/numpy/fft/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/ufunclike.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/type_check.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/npyio.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/_iotools.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/scimath.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/shape_base.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/financial.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/polynomial.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/arraypad.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/index_tricks.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/arrayterator.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/utils.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/mixins.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/function_base.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/stride_tricks.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/histograms.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/_version.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/format.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/user_array.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/_datasource.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/arraysetops.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/recfunctions.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/nanfunctions.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/twodim_base.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/setup.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_format.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_regression.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_arraysetops.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_utils.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test__version.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_shape_base.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_twodim_base.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_type_check.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_histograms.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_mixins.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_packbits.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_ufunclike.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_arrayterator.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_function_base.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_arraypad.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_polynomial.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test__datasource.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_index_tricks.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_stride_tricks.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_recfunctions.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_financial.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_nanfunctions.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test_io.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/lib/tests/test__iotools.py -&gt; build/lib.linux-x86_64-3.10/numpy/lib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/linalg
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/linalg/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/linalg
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/linalg/linalg.py -&gt; build/lib.linux-x86_64-3.10/numpy/linalg
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/linalg/setup.py -&gt; build/lib.linux-x86_64-3.10/numpy/linalg
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/linalg/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/linalg/tests/test_regression.py -&gt; build/lib.linux-x86_64-3.10/numpy/linalg/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/linalg/tests/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/linalg/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/linalg/tests/test_linalg.py -&gt; build/lib.linux-x86_64-3.10/numpy/linalg/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/linalg/tests/test_deprecations.py -&gt; build/lib.linux-x86_64-3.10/numpy/linalg/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/linalg/tests/test_build.py -&gt; build/lib.linux-x86_64-3.10/numpy/linalg/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/ma
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/bench.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/mrecords.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/testutils.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/timer_comparison.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/extras.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/setup.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/core.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/ma/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/tests/test_regression.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/tests/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/tests/test_deprecations.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/tests/test_extras.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/tests/test_core.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/tests/test_old_ma.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/tests/test_subclassing.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/ma/tests/test_mrecords.py -&gt; build/lib.linux-x86_64-3.10/numpy/ma/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/matrixlib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/matrixlib/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/matrixlib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/matrixlib/defmatrix.py -&gt; build/lib.linux-x86_64-3.10/numpy/matrixlib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/matrixlib/setup.py -&gt; build/lib.linux-x86_64-3.10/numpy/matrixlib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/matrixlib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/matrixlib/tests/test_regression.py -&gt; build/lib.linux-x86_64-3.10/numpy/matrixlib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/matrixlib/tests/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/matrixlib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/matrixlib/tests/test_multiarray.py -&gt; build/lib.linux-x86_64-3.10/numpy/matrixlib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/matrixlib/tests/test_defmatrix.py -&gt; build/lib.linux-x86_64-3.10/numpy/matrixlib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/matrixlib/tests/test_numeric.py -&gt; build/lib.linux-x86_64-3.10/numpy/matrixlib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/matrixlib/tests/test_interaction.py -&gt; build/lib.linux-x86_64-3.10/numpy/matrixlib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/matrixlib/tests/test_matrix_linalg.py -&gt; build/lib.linux-x86_64-3.10/numpy/matrixlib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/matrixlib/tests/test_masked_matrix.py -&gt; build/lib.linux-x86_64-3.10/numpy/matrixlib/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/polynomial
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/_polybase.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/hermite_e.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/legendre.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/polynomial.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/polyutils.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/laguerre.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/chebyshev.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/hermite.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/setup.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/polynomial/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/tests/test_laguerre.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/tests/test_chebyshev.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/tests/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/tests/test_legendre.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/tests/test_printing.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/tests/test_hermite_e.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/tests/test_polyutils.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/tests/test_polynomial.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/tests/test_hermite.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/polynomial/tests/test_classes.py -&gt; build/lib.linux-x86_64-3.10/numpy/polynomial/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/random
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/random/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/random
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/random/_pickle.py -&gt; build/lib.linux-x86_64-3.10/numpy/random
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/random/setup.py -&gt; build/lib.linux-x86_64-3.10/numpy/random
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/random/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/random/tests/test_randomstate_regression.py -&gt; build/lib.linux-x86_64-3.10/numpy/random/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/random/tests/test_regression.py -&gt; build/lib.linux-x86_64-3.10/numpy/random/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/random/tests/test_smoke.py -&gt; build/lib.linux-x86_64-3.10/numpy/random/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/random/tests/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/random/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/random/tests/test_random.py -&gt; build/lib.linux-x86_64-3.10/numpy/random/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/random/tests/test_generator_mt19937.py -&gt; build/lib.linux-x86_64-3.10/numpy/random/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/random/tests/test_randomstate.py -&gt; build/lib.linux-x86_64-3.10/numpy/random/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/random/tests/test_generator_mt19937_regressions.py -&gt; build/lib.linux-x86_64-3.10/numpy/random/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/random/tests/test_direct.py -&gt; build/lib.linux-x86_64-3.10/numpy/random/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/random/tests/test_extending.py -&gt; build/lib.linux-x86_64-3.10/numpy/random/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/random/tests/test_seed_sequence.py -&gt; build/lib.linux-x86_64-3.10/numpy/random/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/testing
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/testing/print_coercion_tables.py -&gt; build/lib.linux-x86_64-3.10/numpy/testing
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/testing/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/testing
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/testing/utils.py -&gt; build/lib.linux-x86_64-3.10/numpy/testing
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/testing/setup.py -&gt; build/lib.linux-x86_64-3.10/numpy/testing
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/testing/_private
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/testing/_private/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/testing/_private
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/testing/_private/parameterized.py -&gt; build/lib.linux-x86_64-3.10/numpy/testing/_private
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/testing/_private/noseclasses.py -&gt; build/lib.linux-x86_64-3.10/numpy/testing/_private
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/testing/_private/utils.py -&gt; build/lib.linux-x86_64-3.10/numpy/testing/_private
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/testing/_private/nosetester.py -&gt; build/lib.linux-x86_64-3.10/numpy/testing/_private
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/testing/_private/decorators.py -&gt; build/lib.linux-x86_64-3.10/numpy/testing/_private
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/testing/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/testing/tests/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/testing/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/testing/tests/test_utils.py -&gt; build/lib.linux-x86_64-3.10/numpy/testing/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/testing/tests/test_decorators.py -&gt; build/lib.linux-x86_64-3.10/numpy/testing/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/testing/tests/test_doctesting.py -&gt; build/lib.linux-x86_64-3.10/numpy/testing/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/lib.linux-x86_64-3.10/numpy/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/tests/test_ctypeslib.py -&gt; build/lib.linux-x86_64-3.10/numpy/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/tests/__init__.py -&gt; build/lib.linux-x86_64-3.10/numpy/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/tests/test_warnings.py -&gt; build/lib.linux-x86_64-3.10/numpy/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/tests/test_matlib.py -&gt; build/lib.linux-x86_64-3.10/numpy/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/tests/test_numpy_version.py -&gt; build/lib.linux-x86_64-3.10/numpy/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/tests/test_scripts.py -&gt; build/lib.linux-x86_64-3.10/numpy/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/tests/test_reloading.py -&gt; build/lib.linux-x86_64-3.10/numpy/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> copying numpy/tests/test_public_api.py -&gt; build/lib.linux-x86_64-3.10/numpy/tests
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> running build_clib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> customize UnixCCompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> customize UnixCCompiler using new_build_clib
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building &#39;npymath&#39; library
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> compiling C sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/numpy
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/numpy/core/src
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/numpy/core/src/npymath
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/build
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/npymath
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> compile options: &#39;-Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/npymath/npy_math.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/ieee754.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/npymath/halffloat.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_complex.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> ar: adding 4 object files to build/temp.linux-x86_64-3.10/libnpymath.a
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building &#39;npysort&#39; library
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> compiling C sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/npysort
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> compile options: &#39;-Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/quicksort.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/mergesort.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/heapsort.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/timsort.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/radixsort.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/selection.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/binsearch.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> ar: adding 7 object files to build/temp.linux-x86_64-3.10/libnpysort.a
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building &#39;npyrandom&#39; library
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> compiling C sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/numpy/random
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/numpy/random/src
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/numpy/random/src/distributions
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> compile options: &#39;-Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/random/src/distributions/logfactorial.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/random/src/distributions/distributions.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/random/src/distributions/random_mvhg_count.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/random/src/distributions/random_mvhg_marginals.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/random/src/distributions/random_hypergeometric.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> ar: adding 5 object files to build/temp.linux-x86_64-3.10/libnpyrandom.a
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> running build_ext
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> customize UnixCCompiler
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> customize UnixCCompiler using new_build_ext
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building &#39;numpy.core._multiarray_tests&#39; extension
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> compiling C sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/numpy/core/src/common
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> compile options: &#39;-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/_multiarray_tests.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/common/mem_overlap.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray/_multiarray_tests.o build/temp.linux-x86_64-3.10/numpy/core/src/common/mem_overlap.o -Lbuild/temp.linux-x86_64-3.10 -lnpymath -o build/lib.linux-x86_64-3.10/numpy/core/_multiarray_tests.cpython-310-x86_64-linux-gnu.so
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> building &#39;numpy.core._multiarray_umath&#39; extension
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> compiling C sources
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/numpy/core/src/multiarray
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/numpy/core/src/umath
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/umath
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/common
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> compile options: &#39;-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DSCIPY_MKL_H -DHAVE_CBLAS -I/usr/local/include -I/usr/include -I/opt/conda/include -Ibuild/src.linux-x86_64-3.10/numpy/core/src/umath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/alloc.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/arrayfunction_override.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/convert.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/datetime_strings.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/arrayobject.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/buffer.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/convert_datatype.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/datetime_busday.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/calculation.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/conversion_utils.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/datetime_busdaycal.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/arraytypes.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/compiled_base.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/ctors.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/descriptor.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/common.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/dragon4.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/datetime.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/dtype_transfer.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/item_selection.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/multiarraymodule.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/einsum.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/iterators.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/lowlevel_strided_loops.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/nditer_templ.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/array_assign_scalar.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/array_assign_array.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/nditer_api.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/number.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/flagsobject.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/refcount.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/nditer_constr.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/sequence.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/getset.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/shape.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/hashdescr.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/scalarapi.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src: In function &#39;float_arrtype_hash&#39;:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2967:27: error: incompatible type for argument 1 of &#39;_Py_HashDouble&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> In file included from /opt/conda/include/python3.10/Python.h:77,
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>                  from numpy/core/src/multiarray/scalartypes.c.src:3:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /opt/conda/include/python3.10/pyhash.h:10:38: note: expected &#39;PyObject *&#39; {aka &#39;struct _object *&#39;} but argument is of type &#39;double&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                                      ^~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2967:12: error: too few arguments to function &#39;_Py_HashDouble&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |            ^~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> In file included from /opt/conda/include/python3.10/Python.h:77,
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>                  from numpy/core/src/multiarray/scalartypes.c.src:3:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /opt/conda/include/python3.10/pyhash.h:10:23: note: declared here
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                       ^~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src: In function &#39;cfloat_arrtype_hash&#39;:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2975:31: error: incompatible type for argument 1 of &#39;_Py_HashDouble&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2975 |     hashreal = _Py_HashDouble((double)
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                               ^~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                               |
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                               double
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2976 |             PyArrayScalar_VAL(obj, C@name@).real);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> In file included from /opt/conda/include/python3.10/Python.h:77,
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>                  from numpy/core/src/multiarray/scalartypes.c.src:3:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /opt/conda/include/python3.10/pyhash.h:10:38: note: expected &#39;PyObject *&#39; {aka &#39;struct _object *&#39;} but argument is of type &#39;double&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                                      ^~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2975:16: error: too few arguments to function &#39;_Py_HashDouble&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2975 |     hashreal = _Py_HashDouble((double)
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                ^~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> In file included from /opt/conda/include/python3.10/Python.h:77,
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>                  from numpy/core/src/multiarray/scalartypes.c.src:3:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /opt/conda/include/python3.10/pyhash.h:10:23: note: declared here
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                       ^~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2981:31: error: incompatible type for argument 1 of &#39;_Py_HashDouble&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2981 |     hashimag = _Py_HashDouble((double)
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                               ^~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                               |
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                               double
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2982 |             PyArrayScalar_VAL(obj, C@name@).imag);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> In file included from /opt/conda/include/python3.10/Python.h:77,
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>                  from numpy/core/src/multiarray/scalartypes.c.src:3:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /opt/conda/include/python3.10/pyhash.h:10:38: note: expected &#39;PyObject *&#39; {aka &#39;struct _object *&#39;} but argument is of type &#39;double&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                                      ^~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2981:16: error: too few arguments to function &#39;_Py_HashDouble&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2981 |     hashimag = _Py_HashDouble((double)
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                ^~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> In file included from /opt/conda/include/python3.10/Python.h:77,
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>                  from numpy/core/src/multiarray/scalartypes.c.src:3:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /opt/conda/include/python3.10/pyhash.h:10:23: note: declared here
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                       ^~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src: In function &#39;longdouble_arrtype_hash&#39;:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2967:27: error: incompatible type for argument 1 of &#39;_Py_HashDouble&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> In file included from /opt/conda/include/python3.10/Python.h:77,
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>                  from numpy/core/src/multiarray/scalartypes.c.src:3:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /opt/conda/include/python3.10/pyhash.h:10:38: note: expected &#39;PyObject *&#39; {aka &#39;struct _object *&#39;} but argument is of type &#39;double&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                                      ^~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2967:12: error: too few arguments to function &#39;_Py_HashDouble&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |            ^~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> In file included from /opt/conda/include/python3.10/Python.h:77,
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>                  from numpy/core/src/multiarray/scalartypes.c.src:3:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /opt/conda/include/python3.10/pyhash.h:10:23: note: declared here
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                       ^~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src: In function &#39;clongdouble_arrtype_hash&#39;:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2975:31: error: incompatible type for argument 1 of &#39;_Py_HashDouble&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2975 |     hashreal = _Py_HashDouble((double)
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                               ^~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                               |
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                               double
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2976 |             PyArrayScalar_VAL(obj, C@name@).real);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> In file included from /opt/conda/include/python3.10/Python.h:77,
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>                  from numpy/core/src/multiarray/scalartypes.c.src:3:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /opt/conda/include/python3.10/pyhash.h:10:38: note: expected &#39;PyObject *&#39; {aka &#39;struct _object *&#39;} but argument is of type &#39;double&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                                      ^~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2975:16: error: too few arguments to function &#39;_Py_HashDouble&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2975 |     hashreal = _Py_HashDouble((double)
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                ^~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> In file included from /opt/conda/include/python3.10/Python.h:77,
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>                  from numpy/core/src/multiarray/scalartypes.c.src:3:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /opt/conda/include/python3.10/pyhash.h:10:23: note: declared here
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                       ^~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2981:31: error: incompatible type for argument 1 of &#39;_Py_HashDouble&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2981 |     hashimag = _Py_HashDouble((double)
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                               ^~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                               |
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                               double
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2982 |             PyArrayScalar_VAL(obj, C@name@).imag);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> In file included from /opt/conda/include/python3.10/Python.h:77,
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>                  from numpy/core/src/multiarray/scalartypes.c.src:3:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /opt/conda/include/python3.10/pyhash.h:10:38: note: expected &#39;PyObject *&#39; {aka &#39;struct _object *&#39;} but argument is of type &#39;double&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                                      ^~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2981:16: error: too few arguments to function &#39;_Py_HashDouble&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2981 |     hashimag = _Py_HashDouble((double)
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                ^~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> In file included from /opt/conda/include/python3.10/Python.h:77,
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>                  from numpy/core/src/multiarray/scalartypes.c.src:3:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /opt/conda/include/python3.10/pyhash.h:10:23: note: declared here
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                       ^~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src: In function &#39;half_arrtype_hash&#39;:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2997:27: error: incompatible type for argument 1 of &#39;_Py_HashDouble&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2997 |     return _Py_HashDouble(npy_half_to_double(PyArrayScalar_VAL(obj, Half)));
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                           |
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                           double
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> In file included from /opt/conda/include/python3.10/Python.h:77,
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>                  from numpy/core/src/multiarray/scalartypes.c.src:3:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /opt/conda/include/python3.10/pyhash.h:10:38: note: expected &#39;PyObject *&#39; {aka &#39;struct _object *&#39;} but argument is of type &#39;double&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                                      ^~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2997:12: error: too few arguments to function &#39;_Py_HashDouble&#39;
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2997 |     return _Py_HashDouble(npy_half_to_double(PyArrayScalar_VAL(obj, Half)));
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |            ^~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> In file included from /opt/conda/include/python3.10/Python.h:77,
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>                  from numpy/core/src/multiarray/scalartypes.c.src:3:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> /opt/conda/include/python3.10/pyhash.h:10:23: note: declared here
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       |                       ^~~~~~~~~~~~~~
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src: In function &#39;longdouble_arrtype_hash&#39;:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2968:1: warning: control reaches end of non-void function [-Wreturn-type]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2968 | }
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       | ^
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src: In function &#39;float_arrtype_hash&#39;:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2968:1: warning: control reaches end of non-void function [-Wreturn-type]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2968 | }
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       | ^
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src: In function &#39;half_arrtype_hash&#39;:
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> numpy/core/src/multiarray/scalartypes.c.src:2998:1: warning: control reaches end of non-void function [-Wreturn-type]
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>  2998 | }
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span>       | ^
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/vdot.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/clip.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/nditer_pywrap.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/umath/umathmodule.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/umath/reduction.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/umath/ufunc_object.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/loops.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/umath/override.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/npymath/npy_math.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/ieee754.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_complex.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/npymath/halffloat.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/umath/extobj.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/common/array_assign.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/common/mem_overlap.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/scalarmath.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/common/npy_longdouble.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/common/ucsnarrow.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/common/ufunc_override.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/common/numpyos.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/common/npy_cpu_features.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/common/cblasfuncs.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/common/python_xerbla.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/umath/ufunc_type_resolution.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/mapping.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: numpy/core/src/multiarray/methods.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/matmul.c
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> error: Command &#34;gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DSCIPY_MKL_H -DHAVE_CBLAS -I/usr/local/include -I/usr/include -I/opt/conda/include -Ibuild/src.linux-x86_64-3.10/numpy/core/src/umath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.c -o build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.o -MMD -MF build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.o.d&#34; failed with exit status 1
  <span class="ansi-red-fg">   </span>   <span class="ansi-red-fg">   </span> <span class="ansi-red-fg">[end of output]</span>
  <span class="ansi-red-fg">   </span> 
  <span class="ansi-red-fg">   </span>   <span class="ansi-magenta-intense-fg ansi-bold">note</span>: This error originates from a subprocess, and is likely not a problem with pip.
  <span class="ansi-red-fg">   </span> <span class="ansi-red-fg">  ERROR: Failed building wheel for numpy</span><span class="ansi-red-fg">
  </span><span class="ansi-red-fg">   </span> Failed to build numpy
  <span class="ansi-red-fg">   </span> <span class="ansi-red-fg">ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (numpy)</span><span class="ansi-red-fg">
  </span><span class="ansi-red-fg">   </span> 
  <span class="ansi-red-fg">   </span> <span class="ansi-red-fg">[end of output]</span>
  
  <span class="ansi-magenta-intense-fg ansi-bold">note</span>: This error originates from a subprocess, and is likely not a problem with pip.
<span class="ansi-red-intense-fg ansi-bold">error</span>: <span class="ansi-bold">subprocess-exited-with-error</span>

<span class="ansi-red-fg"></span> <span class="ansi-green-fg">pip subprocess to install build dependencies</span> did not run successfully.
<span class="ansi-red-fg"></span> exit code: <span class="ansi-cyan-intense-fg ansi-bold">1</span>
<span class="ansi-red-fg">&gt;</span> See above for output.

<span class="ansi-magenta-intense-fg ansi-bold">note</span>: This error originates from a subprocess, and is likely not a problem with pip.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Invert requirements to avoid opencv-python-headless error cancelling other installations</span>
<span class="o">!</span>tac requirements.txt &gt; reverse_requirements.txt
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Install requirements</span>
<span class="o">!</span>pip install -r reverse_requirements.txt <span class="p">|</span> grep -v <span class="s2">&quot;already satisfied&quot;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting seaborn==0.11.2 (from -r reverse_requirements.txt (line 1))
  Downloading seaborn-0.11.2-py3-none-any.whl.metadata (2.3 kB)
Collecting pandas==1.3.5 (from -r reverse_requirements.txt (line 2))
  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)
Collecting pytest==7.1.1 (from -r reverse_requirements.txt (line 3))
  Downloading pytest-7.1.1-py3-none-any.whl.metadata (7.8 kB)
Collecting ipywidgets==7.6.5 (from -r reverse_requirements.txt (line 5))
  Downloading ipywidgets-7.6.5-py2.py3-none-any.whl.metadata (1.9 kB)
Collecting tqdm==4.63.0 (from -r reverse_requirements.txt (line 6))
  Downloading tqdm-4.63.0-py2.py3-none-any.whl.metadata (57 kB)
<span class="ansi-red-fg">ERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0</span><span class="ansi-red-fg">
</span><span class="ansi-red-fg">ERROR: Could not find a version that satisfies the requirement torchvision==0.10.0 (from versions: 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0)</span><span class="ansi-red-fg">
</span><span class="ansi-red-fg">ERROR: No matching distribution found for torchvision==0.10.0</span><span class="ansi-red-fg">
</span></pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install <span class="nv">livelossplot</span><span class="o">==</span><span class="m">0</span>.5.4
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: livelossplot==0.5.4 in /opt/conda/lib/python3.10/site-packages (0.5.4)
Requirement already satisfied: ipython in /opt/conda/lib/python3.10/site-packages (from livelossplot==0.5.4) (8.20.0)
Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from livelossplot==0.5.4) (3.7.5)
Requirement already satisfied: bokeh in /opt/conda/lib/python3.10/site-packages (from livelossplot==0.5.4) (3.4.2)
Requirement already satisfied: Jinja2&gt;=2.9 in /opt/conda/lib/python3.10/site-packages (from bokeh-&gt;livelossplot==0.5.4) (3.1.2)
Requirement already satisfied: contourpy&gt;=1.2 in /opt/conda/lib/python3.10/site-packages (from bokeh-&gt;livelossplot==0.5.4) (1.2.0)
Requirement already satisfied: numpy&gt;=1.16 in /opt/conda/lib/python3.10/site-packages (from bokeh-&gt;livelossplot==0.5.4) (1.26.4)
Requirement already satisfied: packaging&gt;=16.8 in /opt/conda/lib/python3.10/site-packages (from bokeh-&gt;livelossplot==0.5.4) (21.3)
Requirement already satisfied: pandas&gt;=1.2 in /opt/conda/lib/python3.10/site-packages (from bokeh-&gt;livelossplot==0.5.4) (2.2.2)
Requirement already satisfied: pillow&gt;=7.1.0 in /opt/conda/lib/python3.10/site-packages (from bokeh-&gt;livelossplot==0.5.4) (9.5.0)
Requirement already satisfied: PyYAML&gt;=3.10 in /opt/conda/lib/python3.10/site-packages (from bokeh-&gt;livelossplot==0.5.4) (6.0.1)
Requirement already satisfied: tornado&gt;=6.2 in /opt/conda/lib/python3.10/site-packages (from bokeh-&gt;livelossplot==0.5.4) (6.3.3)
Requirement already satisfied: xyzservices&gt;=2021.09.1 in /opt/conda/lib/python3.10/site-packages (from bokeh-&gt;livelossplot==0.5.4) (2024.6.0)
Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython-&gt;livelossplot==0.5.4) (5.1.1)
Requirement already satisfied: jedi&gt;=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython-&gt;livelossplot==0.5.4) (0.19.1)
Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython-&gt;livelossplot==0.5.4) (0.1.6)
Requirement already satisfied: prompt-toolkit&lt;3.1.0,&gt;=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython-&gt;livelossplot==0.5.4) (3.0.42)
Requirement already satisfied: pygments&gt;=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython-&gt;livelossplot==0.5.4) (2.17.2)
Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython-&gt;livelossplot==0.5.4) (0.6.2)
Requirement already satisfied: traitlets&gt;=5 in /opt/conda/lib/python3.10/site-packages (from ipython-&gt;livelossplot==0.5.4) (5.9.0)
Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython-&gt;livelossplot==0.5.4) (1.2.0)
Requirement already satisfied: pexpect&gt;4.3 in /opt/conda/lib/python3.10/site-packages (from ipython-&gt;livelossplot==0.5.4) (4.8.0)
Requirement already satisfied: cycler&gt;=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib-&gt;livelossplot==0.5.4) (0.12.1)
Requirement already satisfied: fonttools&gt;=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib-&gt;livelossplot==0.5.4) (4.47.0)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib-&gt;livelossplot==0.5.4) (1.4.5)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib-&gt;livelossplot==0.5.4) (3.1.1)
Requirement already satisfied: python-dateutil&gt;=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib-&gt;livelossplot==0.5.4) (2.9.0.post0)
Requirement already satisfied: parso&lt;0.9.0,&gt;=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi&gt;=0.16-&gt;ipython-&gt;livelossplot==0.5.4) (0.8.3)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2&gt;=2.9-&gt;bokeh-&gt;livelossplot==0.5.4) (2.1.3)
Requirement already satisfied: pytz&gt;=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas&gt;=1.2-&gt;bokeh-&gt;livelossplot==0.5.4) (2023.3.post1)
Requirement already satisfied: tzdata&gt;=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas&gt;=1.2-&gt;bokeh-&gt;livelossplot==0.5.4) (2023.4)
Requirement already satisfied: ptyprocess&gt;=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect&gt;4.3-&gt;ipython-&gt;livelossplot==0.5.4) (0.7.0)
Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit&lt;3.1.0,&gt;=3.0.41-&gt;ipython-&gt;livelossplot==0.5.4) (0.2.13)
Requirement already satisfied: six&gt;=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib-&gt;livelossplot==0.5.4) (1.16.0)
Requirement already satisfied: executing&gt;=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data-&gt;ipython-&gt;livelossplot==0.5.4) (2.0.1)
Requirement already satisfied: asttokens&gt;=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data-&gt;ipython-&gt;livelossplot==0.5.4) (2.4.1)
Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data-&gt;ipython-&gt;livelossplot==0.5.4) (0.2.2)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">src.helpers</span> <span class="kn">import</span> <span class="n">setup_env</span>

<span class="c1"># If running locally, this will download dataset (make sure you have at</span>
<span class="c1"># least 2 Gb of space on your hard drive)</span>
<span class="n">setup_env</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>GPU available
Downloading and unzipping https://udacity-dlnfd.s3-us-west-1.amazonaws.com/datasets/landmark_images.zip. This will take a while...
done
Reusing cached mean and std
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="-Step-1:-Create-transfer-learning-architecture"><img alt="&gt;" src="https://github.com/nathanbangwa243/udpj-landmark-classification/blob/main/static_images/icons/noun-advance-2109145.png?raw=1" style="width:50px" /> Step 1: Create transfer learning architecture<a class="anchor-link" href="#-Step-1:-Create-transfer-learning-architecture">&#182;</a></h2><p>Open the file <code>src/transfer.py</code> and complete the <code>get_model_transfer_learning</code> function. When you are done, execute this test:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pytest -vv src/transfer.py
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform linux -- Python 3.10.13, pytest-8.2.2, pluggy-1.5.0 -- /opt/conda/bin/python3.10
cachedir: .pytest_cache
rootdir: /kaggle/working
plugins: anyio-4.2.0, typeguard-4.1.5
collected 1 item                                                               <span class="ansi-bold">

src/transfer.py::test_get_model_transfer_learning </span><span class="ansi-green-intense-fg ansi-bold">PASSED</span><span class="ansi-green-fg">                 [100%]</span>

<span class="ansi-yellow-fg">=============================== warnings summary ===============================</span>
src/transfer.py::test_get_model_transfer_learning
  /opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter &#39;pretrained&#39; is deprecated since 0.13 and may be removed in the future, please use &#39;weights&#39; instead.
    warnings.warn(

src/transfer.py::test_get_model_transfer_learning
  /opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for &#39;weights&#39; are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
    warnings.warn(msg)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
<span class="ansi-yellow-fg">======================== </span><span class="ansi-green-fg">1 passed</span>, <span class="ansi-yellow-intense-fg ansi-bold">2 warnings</span><span class="ansi-yellow-fg"> in 4.62s</span><span class="ansi-yellow-fg"> =========================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="-Step-2:-Train,-validation-and-test"><img alt="&gt;" src="https://github.com/nathanbangwa243/udpj-landmark-classification/blob/main/static_images/icons/noun-advance-2109145.png?raw=1" style="width:50px" /> Step 2: Train, validation and test<a class="anchor-link" href="#-Step-2:-Train,-validation-and-test">&#182;</a></h2><p>Let's train our transfer learning model! Let's start defining the hyperparameters:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>  <span class="c1"># size of the minibatch for stochastic gradient descent (or Adam)</span>
<span class="n">valid_size</span> <span class="o">=</span> <span class="mf">0.2</span>  <span class="c1"># fraction of the training data to reserve for validation</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># number of epochs for training</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># number of classes. Do not change this</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>  <span class="c1"># Learning rate for SGD (or Adam)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="s1">&#39;adam&#39;</span>      <span class="c1"># optimizer. &#39;sgd&#39; or &#39;adam&#39;</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c1"># regularization. Increase this to combat overfitting</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">src.data</span> <span class="kn">import</span> <span class="n">get_data_loaders</span>
<span class="kn">from</span> <span class="nn">src.optimization</span> <span class="kn">import</span> <span class="n">get_optimizer</span><span class="p">,</span> <span class="n">get_loss</span>
<span class="kn">from</span> <span class="nn">src.train</span> <span class="kn">import</span> <span class="n">optimize</span>
<span class="kn">from</span> <span class="nn">src.transfer</span> <span class="kn">import</span> <span class="n">get_model_transfer_learning</span>

<span class="c1"># Get a model using get_model_transfer_learning. Use one of the names reported here:</span>
<span class="c1"># https://pytorch.org/vision/0.10/models.html</span>
<span class="c1"># For example, if you want to load ResNet 18, use &quot;resnet18&quot;</span>
<span class="c1"># NOTE: use the hyperparameters defined in the previous cell, do NOT copy/paste the</span>
<span class="c1"># values</span>
<span class="c1"># YOUR CODE HERE</span>
<span class="n">model_transfer</span> <span class="o">=</span> <span class="n">get_model_transfer_learning</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;resnet18&quot;</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>


<span class="c1"># train the model</span>
<span class="n">data_loaders</span> <span class="o">=</span> <span class="n">get_data_loaders</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">get_optimizer</span><span class="p">(</span>
    <span class="n">model_transfer</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">get_loss</span><span class="p">()</span>

<span class="n">optimize</span><span class="p">(</span>
    <span class="n">data_loaders</span><span class="p">,</span>
    <span class="n">model_transfer</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">,</span>
    <span class="n">loss</span><span class="p">,</span>
    <span class="n">n_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
    <span class="n">save_path</span><span class="o">=</span><span class="s2">&quot;checkpoints/model_transfer.pt&quot;</span><span class="p">,</span>
    <span class="n">interactive_tracking</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/nathanbangwa243/udpj-landmark-classification/blob/main/static_images/icons/noun-question-mark-869751.png?raw=1" alt="?" style="width:25px"/> <strong>Question:</strong> Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  Describe why you think the architecture is suitable for the current problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/nathanbangwa243/udpj-landmark-classification/blob/main/static_images/icons/noun-answer-3361020.png?raw=1" alt=">" style="width:25px"/>  <strong>Answer:</strong></p>
<p>I chose ResNet18 as the base model for my architecture because it offers a good balance between performance and model size, performing well on ImageNet, which is similar in nature to the landmark classification task. ResNet18's architecture includes residual connections that help mitigate the vanishing gradient problem and allows deeper networks to be trained effectively.</p>
<p>Since ResNet18 was pre-trained on ImageNet, it already has learned rich feature representations for natural scenes. This makes it particularly suitable for landmark classification, which also involves analyzing images of natural scenes.</p>
<p>To adapt ResNet18 for the landmark classification task, I froze its pre-trained layers to use it as a feature extractor and replaced the final classification layer. The new classification head includes a sequence of fully connected layers with dropout for regularization. This configuration is designed to fine-tune the model for the specific number of landmark classes while leveraging the pre-trained features effectively.</p>
<p>This approach ensures that the model benefits from the robust feature extraction capabilities of ResNet18 while being customized to classify landmarks with the appropriate number of output classes.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now play with the hyperparameters and see which performance you can get on the validation set. You should get at least 60% for a passing grade, but a good model choice and a good training strategy could get you up to 80% or so. Let's see how close you can get!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="-Step-3:-Test-the-Model"><img alt="&gt;" src="https://github.com/nathanbangwa243/udpj-landmark-classification/blob/main/static_images/icons/noun-advance-2109145.png?raw=1" style="width:50px" /> Step 3: Test the Model<a class="anchor-link" href="#-Step-3:-Test-the-Model">&#182;</a></h2><p>Try out your model on the test dataset of landmark images. Use the code cell below to calculate and print the test loss and accuracy.  Ensure that your test accuracy is greater than 60% and matches more or less what you got on the validation set (otherwise you're overfitting!)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">src.train</span> <span class="kn">import</span> <span class="n">one_epoch_test</span>
<span class="kn">from</span> <span class="nn">src.transfer</span> <span class="kn">import</span> <span class="n">get_model_transfer_learning</span>

<span class="n">model_transfer</span> <span class="o">=</span> <span class="n">get_model_transfer_learning</span><span class="p">(</span><span class="s2">&quot;resnet18&quot;</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>
<span class="c1"># Load saved weights</span>
<span class="n">model_transfer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;checkpoints/model_transfer.pt&#39;</span><span class="p">))</span>

<span class="n">one_epoch_test</span><span class="p">(</span><span class="n">data_loaders</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">model_transfer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Testing: 100%|| 20/20 [00:04&lt;00:00,  4.41it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test Loss: 0.961142


Test Accuracy: 73% (918/1250)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[29]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9611424028873443</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#128522;-Look-how-beautiful-it-is">&#128522; Look how beautiful it is<a class="anchor-link" href="#&#128522;-Look-how-beautiful-it-is">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="-Step-4:-Export-using-torchscript"><img alt="&gt;" src="https://github.com/nathanbangwa243/udpj-landmark-classification/blob/main/static_images/icons/noun-advance-2109145.png?raw=1" style="width:50px" /> Step 4: Export using torchscript<a class="anchor-link" href="#-Step-4:-Export-using-torchscript">&#182;</a></h2><p>Now, just like we did with our original model, we export the best fit model using torchscript so that it can be used in our application:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">src.predictor</span> <span class="kn">import</span> <span class="n">Predictor</span>
<span class="kn">from</span> <span class="nn">src.helpers</span> <span class="kn">import</span> <span class="n">compute_mean_and_std</span>

<span class="c1"># First let&#39;s get the class names from our data loaders</span>
<span class="n">class_names</span> <span class="o">=</span> <span class="n">data_loaders</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">classes</span>

<span class="c1"># Then let&#39;s move the model_transfer to the CPU</span>
<span class="c1"># (we don&#39;t need GPU for inference)</span>
<span class="n">model_transfer</span> <span class="o">=</span> <span class="n">model_transfer</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="c1"># Let&#39;s make sure we use the right weights by loading the</span>
<span class="c1"># best weights we have found during training</span>
<span class="c1"># NOTE: remember to use map_location=&#39;cpu&#39; so the weights</span>
<span class="c1"># are loaded on the CPU (and not the GPU)</span>
<span class="n">model_transfer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;checkpoints/model_transfer.pt&quot;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Let&#39;s wrap our model using the predictor class</span>
<span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">compute_mean_and_std</span><span class="p">()</span>
<span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="p">(</span><span class="n">model_transfer</span><span class="p">,</span> <span class="n">class_names</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

<span class="c1"># Export using torch.jit.script</span>
<span class="n">scripted_predictor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span><span class="p">(</span><span class="n">predictor</span><span class="p">)</span>
<span class="n">scripted_predictor</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;checkpoints/transfer_exported.pt&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Reusing cached mean and std
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">src.predictor</span> <span class="kn">import</span> <span class="n">predictor_test</span>
<span class="kn">from</span> <span class="nn">src.helpers</span> <span class="kn">import</span> <span class="n">plot_confusion_matrix</span>

<span class="n">model_reloaded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;checkpoints/transfer_exported.pt&quot;</span><span class="p">)</span>

<span class="n">pred</span><span class="p">,</span> <span class="n">truth</span> <span class="o">=</span> <span class="n">predictor_test</span><span class="p">(</span><span class="n">data_loaders</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">model_reloaded</span><span class="p">)</span>

<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">truth</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|                                                  | 0/1250 [00:00&lt;?, ?it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  0%|                                          | 1/1250 [00:00&lt;06:22,  3.26it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  0%|                                          | 2/1250 [00:00&lt;04:24,  4.71it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  0%|                                         | 5/1250 [00:00&lt;01:49, 11.34it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  1%|                                         | 8/1250 [00:00&lt;01:17, 16.07it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  1%|                                        | 11/1250 [00:00&lt;01:03, 19.46it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  1%|                                        | 14/1250 [00:00&lt;00:57, 21.41it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  1%|                                        | 17/1250 [00:01&lt;00:53, 23.11it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  2%|                                        | 20/1250 [00:01&lt;00:50, 24.32it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  2%|                                        | 23/1250 [00:01&lt;00:48, 25.38it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  2%|                                        | 26/1250 [00:01&lt;00:47, 25.72it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  2%|                                        | 29/1250 [00:01&lt;00:46, 26.30it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  3%|                                        | 32/1250 [00:01&lt;00:45, 26.55it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  3%|                                       | 35/1250 [00:01&lt;00:45, 26.61it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  3%|                                       | 38/1250 [00:01&lt;00:45, 26.62it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  3%|                                       | 41/1250 [00:01&lt;00:45, 26.51it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  4%|                                       | 44/1250 [00:02&lt;00:45, 26.46it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  4%|                                       | 47/1250 [00:02&lt;00:44, 26.85it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  4%|                                       | 50/1250 [00:02&lt;00:44, 27.19it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  4%|                                       | 53/1250 [00:02&lt;00:43, 27.40it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  4%|                                       | 56/1250 [00:02&lt;00:43, 27.65it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  5%|                                       | 59/1250 [00:02&lt;00:43, 27.10it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  5%|                                       | 62/1250 [00:02&lt;00:45, 26.32it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  5%|                                      | 65/1250 [00:02&lt;00:44, 26.43it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  5%|                                      | 68/1250 [00:02&lt;00:45, 26.26it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  6%|                                      | 71/1250 [00:03&lt;00:45, 25.68it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  6%|                                      | 74/1250 [00:03&lt;00:44, 26.40it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  6%|                                      | 77/1250 [00:03&lt;00:44, 26.19it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  6%|                                      | 80/1250 [00:03&lt;00:43, 26.70it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  7%|                                      | 83/1250 [00:03&lt;00:44, 26.33it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  7%|                                      | 86/1250 [00:03&lt;00:44, 26.22it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  7%|                                      | 89/1250 [00:03&lt;00:43, 26.42it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  7%|                                      | 92/1250 [00:03&lt;00:45, 25.40it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  8%|                                      | 95/1250 [00:03&lt;00:46, 24.78it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  8%|                                     | 98/1250 [00:04&lt;00:46, 24.97it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  8%|                                    | 101/1250 [00:04&lt;00:46, 24.74it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  8%|                                    | 104/1250 [00:04&lt;00:44, 25.51it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  9%|                                    | 107/1250 [00:04&lt;00:44, 25.94it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  9%|                                    | 110/1250 [00:04&lt;00:43, 26.00it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  9%|                                    | 113/1250 [00:04&lt;00:43, 25.84it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  9%|                                    | 116/1250 [00:04&lt;00:44, 25.72it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 10%|                                    | 119/1250 [00:04&lt;00:43, 25.81it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 10%|                                    | 122/1250 [00:05&lt;00:44, 25.44it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 10%|                                    | 125/1250 [00:05&lt;00:43, 25.60it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 10%|                                    | 128/1250 [00:05&lt;00:43, 26.03it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 10%|                                   | 131/1250 [00:05&lt;00:42, 26.04it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 11%|                                   | 134/1250 [00:05&lt;00:41, 26.80it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 11%|                                   | 137/1250 [00:05&lt;00:42, 26.31it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 11%|                                   | 140/1250 [00:05&lt;00:43, 25.62it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 11%|                                   | 143/1250 [00:05&lt;00:42, 25.86it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 12%|                                   | 146/1250 [00:05&lt;00:42, 26.27it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 12%|                                   | 149/1250 [00:06&lt;00:42, 25.89it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 12%|                                   | 152/1250 [00:06&lt;00:42, 25.70it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 12%|                                   | 155/1250 [00:06&lt;00:43, 25.30it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 13%|                                   | 158/1250 [00:06&lt;00:42, 25.60it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 13%|                                  | 161/1250 [00:06&lt;00:42, 25.53it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 13%|                                  | 164/1250 [00:06&lt;00:42, 25.72it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 13%|                                  | 167/1250 [00:06&lt;00:41, 26.08it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 14%|                                  | 170/1250 [00:06&lt;00:41, 26.32it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 14%|                                  | 173/1250 [00:06&lt;00:41, 26.27it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 14%|                                  | 176/1250 [00:07&lt;00:41, 25.95it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 14%|                                  | 179/1250 [00:07&lt;00:41, 25.93it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 15%|                                  | 182/1250 [00:07&lt;00:41, 25.90it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 15%|                                  | 185/1250 [00:07&lt;00:41, 25.81it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 15%|                                  | 188/1250 [00:07&lt;00:40, 26.39it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 15%|                                  | 191/1250 [00:07&lt;00:41, 25.79it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 16%|                                 | 194/1250 [00:07&lt;00:40, 25.77it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 16%|                                 | 197/1250 [00:07&lt;00:41, 25.49it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 16%|                                 | 200/1250 [00:08&lt;00:40, 25.71it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 16%|                                 | 203/1250 [00:08&lt;00:40, 25.84it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 16%|                                 | 206/1250 [00:08&lt;00:41, 25.34it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 17%|                                 | 209/1250 [00:08&lt;00:40, 25.78it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 17%|                                 | 212/1250 [00:08&lt;00:39, 26.17it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 17%|                                 | 215/1250 [00:08&lt;00:39, 26.08it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 17%|                                 | 218/1250 [00:08&lt;00:39, 26.09it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 18%|                                 | 221/1250 [00:08&lt;00:39, 26.18it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 18%|                                | 224/1250 [00:08&lt;00:39, 25.78it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 18%|                                | 227/1250 [00:09&lt;00:39, 25.85it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 18%|                                | 230/1250 [00:09&lt;00:38, 26.20it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 19%|                                | 233/1250 [00:09&lt;00:39, 25.68it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 19%|                                | 236/1250 [00:09&lt;00:39, 25.47it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 19%|                                | 239/1250 [00:09&lt;00:39, 25.44it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 19%|                                | 242/1250 [00:09&lt;00:38, 26.05it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 20%|                                | 245/1250 [00:09&lt;00:38, 25.77it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 20%|                                | 248/1250 [00:09&lt;00:38, 25.82it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 20%|                                | 251/1250 [00:09&lt;00:38, 25.87it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 20%|                               | 254/1250 [00:10&lt;00:41, 23.90it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 21%|                               | 257/1250 [00:10&lt;00:41, 24.19it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 21%|                               | 260/1250 [00:10&lt;00:40, 24.52it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 21%|                               | 263/1250 [00:10&lt;00:40, 24.56it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 21%|                               | 266/1250 [00:10&lt;00:39, 24.93it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 22%|                               | 269/1250 [00:10&lt;00:38, 25.44it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 22%|                               | 272/1250 [00:10&lt;00:37, 25.99it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 22%|                               | 275/1250 [00:10&lt;00:37, 25.84it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 22%|                               | 278/1250 [00:11&lt;00:37, 25.98it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 22%|                               | 281/1250 [00:11&lt;00:36, 26.29it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 23%|                               | 284/1250 [00:11&lt;00:36, 26.23it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 23%|                              | 287/1250 [00:11&lt;00:36, 26.54it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 23%|                              | 290/1250 [00:11&lt;00:36, 26.39it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 23%|                              | 293/1250 [00:11&lt;00:36, 26.41it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 24%|                              | 296/1250 [00:11&lt;00:36, 26.43it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 24%|                              | 299/1250 [00:11&lt;00:35, 26.64it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 24%|                              | 302/1250 [00:11&lt;00:35, 26.87it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 24%|                              | 305/1250 [00:12&lt;00:35, 26.86it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 25%|                              | 308/1250 [00:12&lt;00:35, 26.83it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 25%|                              | 311/1250 [00:12&lt;00:35, 26.58it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 25%|                              | 314/1250 [00:12&lt;00:35, 26.31it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 25%|                             | 317/1250 [00:12&lt;00:35, 26.24it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 26%|                             | 320/1250 [00:12&lt;00:34, 26.60it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 26%|                             | 323/1250 [00:12&lt;00:34, 26.74it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 26%|                             | 326/1250 [00:12&lt;00:36, 25.38it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 26%|                             | 329/1250 [00:13&lt;00:35, 26.02it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 27%|                             | 332/1250 [00:13&lt;00:35, 26.06it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 27%|                             | 335/1250 [00:13&lt;00:34, 26.44it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 27%|                             | 338/1250 [00:13&lt;00:34, 26.62it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 27%|                             | 341/1250 [00:13&lt;00:33, 27.28it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 28%|                             | 344/1250 [00:13&lt;00:33, 26.86it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 28%|                             | 347/1250 [00:13&lt;00:34, 25.85it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 28%|                            | 350/1250 [00:13&lt;00:35, 25.40it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 28%|                            | 353/1250 [00:13&lt;00:36, 24.41it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 28%|                            | 356/1250 [00:14&lt;00:37, 23.74it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 29%|                            | 359/1250 [00:14&lt;00:37, 23.62it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 29%|                            | 362/1250 [00:14&lt;00:36, 24.52it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 29%|                            | 365/1250 [00:14&lt;00:34, 25.42it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 29%|                            | 368/1250 [00:14&lt;00:33, 26.18it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 30%|                            | 371/1250 [00:14&lt;00:33, 26.48it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 30%|                            | 374/1250 [00:14&lt;00:32, 26.80it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 30%|                            | 377/1250 [00:14&lt;00:32, 26.73it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 30%|                           | 380/1250 [00:14&lt;00:32, 26.40it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 31%|                           | 383/1250 [00:15&lt;00:33, 26.18it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 31%|                           | 386/1250 [00:15&lt;00:33, 25.65it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 31%|                           | 389/1250 [00:15&lt;00:33, 25.47it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 31%|                           | 392/1250 [00:15&lt;00:32, 26.06it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 32%|                           | 395/1250 [00:15&lt;00:32, 26.06it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 32%|                           | 398/1250 [00:15&lt;00:32, 26.57it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 32%|                           | 401/1250 [00:15&lt;00:31, 26.66it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 32%|                           | 404/1250 [00:15&lt;00:31, 26.75it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 33%|                           | 407/1250 [00:16&lt;00:31, 26.44it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 33%|                           | 410/1250 [00:16&lt;00:31, 26.33it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 33%|                          | 413/1250 [00:16&lt;00:31, 26.59it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 33%|                          | 416/1250 [00:16&lt;00:31, 26.87it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 34%|                          | 419/1250 [00:16&lt;00:30, 27.02it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 34%|                          | 422/1250 [00:16&lt;00:30, 27.21it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 34%|                          | 425/1250 [00:16&lt;00:30, 27.27it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 34%|                          | 428/1250 [00:16&lt;00:29, 27.40it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 34%|                          | 431/1250 [00:16&lt;00:30, 27.02it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 35%|                          | 434/1250 [00:17&lt;00:31, 26.30it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 35%|                          | 437/1250 [00:17&lt;00:31, 26.14it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 35%|                          | 440/1250 [00:17&lt;00:31, 25.60it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 35%|                         | 443/1250 [00:17&lt;00:30, 26.09it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 36%|                         | 446/1250 [00:17&lt;00:31, 25.53it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 36%|                         | 449/1250 [00:17&lt;00:32, 25.00it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 36%|                         | 452/1250 [00:17&lt;00:31, 25.73it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 36%|                         | 455/1250 [00:17&lt;00:30, 26.09it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 37%|                         | 458/1250 [00:17&lt;00:30, 25.97it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 37%|                         | 461/1250 [00:18&lt;00:30, 25.88it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 37%|                         | 464/1250 [00:18&lt;00:30, 25.85it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 37%|                         | 467/1250 [00:18&lt;00:29, 26.35it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 38%|                         | 470/1250 [00:18&lt;00:28, 26.91it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 38%|                        | 473/1250 [00:18&lt;00:29, 26.45it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 38%|                        | 476/1250 [00:18&lt;00:29, 26.47it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 38%|                        | 479/1250 [00:18&lt;00:28, 26.64it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 39%|                        | 482/1250 [00:18&lt;00:28, 26.99it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 39%|                        | 485/1250 [00:18&lt;00:28, 26.71it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 39%|                        | 488/1250 [00:19&lt;00:28, 26.51it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 39%|                        | 491/1250 [00:19&lt;00:28, 26.58it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 40%|                        | 494/1250 [00:19&lt;00:28, 26.52it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 40%|                        | 497/1250 [00:19&lt;00:28, 26.14it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 40%|                        | 500/1250 [00:19&lt;00:28, 26.62it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 40%|                        | 503/1250 [00:19&lt;00:28, 26.33it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 40%|                       | 506/1250 [00:19&lt;00:28, 26.19it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 41%|                       | 509/1250 [00:19&lt;00:28, 25.82it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 41%|                       | 512/1250 [00:20&lt;00:28, 25.86it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 41%|                       | 515/1250 [00:20&lt;00:30, 23.93it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 41%|                       | 518/1250 [00:20&lt;00:30, 23.85it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 42%|                       | 521/1250 [00:20&lt;00:29, 24.37it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 42%|                       | 524/1250 [00:20&lt;00:29, 24.98it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 42%|                       | 527/1250 [00:20&lt;00:27, 25.87it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 42%|                       | 530/1250 [00:20&lt;00:27, 26.08it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 43%|                       | 533/1250 [00:20&lt;00:26, 26.59it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 43%|                      | 536/1250 [00:20&lt;00:26, 26.73it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 43%|                      | 539/1250 [00:21&lt;00:26, 26.47it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 43%|                      | 542/1250 [00:21&lt;00:26, 26.27it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 44%|                      | 545/1250 [00:21&lt;00:26, 26.43it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 44%|                      | 548/1250 [00:21&lt;00:26, 26.72it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 44%|                      | 551/1250 [00:21&lt;00:26, 26.88it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 44%|                      | 554/1250 [00:21&lt;00:25, 26.95it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 45%|                      | 557/1250 [00:21&lt;00:25, 27.03it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 45%|                      | 560/1250 [00:21&lt;00:25, 27.06it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 45%|                      | 563/1250 [00:21&lt;00:25, 27.15it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 45%|                      | 566/1250 [00:22&lt;00:25, 27.27it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 46%|                     | 569/1250 [00:22&lt;00:25, 26.80it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 46%|                     | 572/1250 [00:22&lt;00:26, 25.68it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 46%|                     | 575/1250 [00:22&lt;00:25, 26.30it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 46%|                     | 578/1250 [00:22&lt;00:25, 26.31it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 46%|                     | 581/1250 [00:22&lt;00:25, 26.28it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 47%|                     | 584/1250 [00:22&lt;00:25, 25.73it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 47%|                     | 587/1250 [00:22&lt;00:25, 25.63it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 47%|                     | 590/1250 [00:22&lt;00:25, 25.45it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 47%|                     | 593/1250 [00:23&lt;00:25, 26.05it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 48%|                     | 596/1250 [00:23&lt;00:25, 25.83it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 48%|                    | 599/1250 [00:23&lt;00:24, 26.35it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 48%|                    | 602/1250 [00:23&lt;00:24, 26.36it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 48%|                    | 605/1250 [00:23&lt;00:24, 26.16it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 49%|                    | 608/1250 [00:23&lt;00:24, 26.18it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 49%|                    | 611/1250 [00:23&lt;00:24, 26.29it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 49%|                    | 614/1250 [00:23&lt;00:24, 26.24it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 49%|                    | 617/1250 [00:24&lt;00:24, 25.78it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 50%|                    | 620/1250 [00:24&lt;00:24, 25.70it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 50%|                    | 623/1250 [00:24&lt;00:24, 25.33it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 50%|                    | 626/1250 [00:24&lt;00:24, 25.15it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 50%|                   | 629/1250 [00:24&lt;00:24, 25.36it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 51%|                   | 632/1250 [00:24&lt;00:25, 24.60it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 51%|                   | 635/1250 [00:24&lt;00:24, 24.73it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 51%|                   | 638/1250 [00:24&lt;00:24, 24.98it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 51%|                   | 641/1250 [00:24&lt;00:23, 25.50it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 52%|                   | 644/1250 [00:25&lt;00:23, 25.62it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 52%|                   | 647/1250 [00:25&lt;00:23, 25.28it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 52%|                   | 650/1250 [00:25&lt;00:23, 25.60it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 52%|                   | 653/1250 [00:25&lt;00:23, 25.26it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 52%|                   | 656/1250 [00:25&lt;00:23, 25.74it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 53%|                   | 659/1250 [00:25&lt;00:22, 26.34it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 53%|                  | 662/1250 [00:25&lt;00:22, 25.96it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 53%|                  | 665/1250 [00:25&lt;00:23, 24.99it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 53%|                  | 668/1250 [00:26&lt;00:23, 24.85it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 54%|                  | 671/1250 [00:26&lt;00:23, 24.67it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 54%|                  | 674/1250 [00:26&lt;00:23, 24.54it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 54%|                  | 677/1250 [00:26&lt;00:23, 24.71it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 54%|                  | 680/1250 [00:26&lt;00:22, 25.14it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 55%|                  | 683/1250 [00:26&lt;00:22, 25.10it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 55%|                  | 686/1250 [00:26&lt;00:22, 25.43it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 55%|                  | 689/1250 [00:26&lt;00:22, 25.41it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 55%|                 | 692/1250 [00:27&lt;00:22, 24.65it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 56%|                 | 695/1250 [00:27&lt;00:23, 24.11it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 56%|                 | 698/1250 [00:27&lt;00:23, 23.94it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 56%|                 | 701/1250 [00:27&lt;00:22, 24.02it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 56%|                 | 704/1250 [00:27&lt;00:23, 23.07it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 57%|                 | 707/1250 [00:27&lt;00:23, 23.41it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 57%|                 | 710/1250 [00:27&lt;00:22, 24.43it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 57%|                 | 713/1250 [00:27&lt;00:21, 25.09it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 57%|                 | 716/1250 [00:27&lt;00:21, 25.36it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 58%|                 | 719/1250 [00:28&lt;00:21, 24.98it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 58%|                 | 722/1250 [00:28&lt;00:20, 25.48it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 58%|                | 725/1250 [00:28&lt;00:20, 25.76it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 58%|                | 728/1250 [00:28&lt;00:20, 25.40it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 58%|                | 731/1250 [00:28&lt;00:23, 22.55it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 59%|                | 734/1250 [00:28&lt;00:23, 22.04it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 59%|                | 737/1250 [00:28&lt;00:24, 20.99it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 59%|                | 740/1250 [00:29&lt;00:27, 18.77it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 59%|                | 742/1250 [00:29&lt;00:28, 18.10it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 60%|                | 744/1250 [00:29&lt;00:28, 18.02it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 60%|                | 746/1250 [00:29&lt;00:27, 18.35it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 60%|                | 748/1250 [00:29&lt;00:27, 18.02it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 60%|                | 750/1250 [00:29&lt;00:27, 18.32it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 60%|                | 752/1250 [00:29&lt;00:27, 18.27it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 60%|               | 754/1250 [00:29&lt;00:27, 18.04it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 60%|               | 756/1250 [00:30&lt;00:27, 17.75it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 61%|               | 758/1250 [00:30&lt;00:30, 16.22it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 61%|               | 761/1250 [00:30&lt;00:27, 18.06it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 61%|               | 764/1250 [00:30&lt;00:23, 20.62it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 61%|               | 767/1250 [00:30&lt;00:21, 22.14it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 62%|               | 770/1250 [00:30&lt;00:21, 22.69it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 62%|               | 773/1250 [00:30&lt;00:19, 23.98it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 62%|               | 776/1250 [00:30&lt;00:19, 24.81it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 62%|               | 779/1250 [00:31&lt;00:18, 25.33it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 63%|               | 782/1250 [00:31&lt;00:18, 25.09it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 63%|               | 785/1250 [00:31&lt;00:18, 25.49it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 63%|              | 788/1250 [00:31&lt;00:18, 25.56it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 63%|              | 791/1250 [00:31&lt;00:17, 25.87it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 64%|              | 794/1250 [00:31&lt;00:17, 25.76it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 64%|              | 797/1250 [00:31&lt;00:17, 25.81it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 64%|              | 800/1250 [00:31&lt;00:17, 26.19it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 64%|              | 803/1250 [00:31&lt;00:17, 25.93it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 64%|              | 806/1250 [00:32&lt;00:17, 25.94it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 65%|              | 809/1250 [00:32&lt;00:17, 25.91it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 65%|              | 812/1250 [00:32&lt;00:16, 26.19it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 65%|              | 815/1250 [00:32&lt;00:16, 26.15it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 65%|             | 818/1250 [00:32&lt;00:16, 26.18it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 66%|             | 821/1250 [00:32&lt;00:16, 26.17it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 66%|             | 824/1250 [00:32&lt;00:16, 25.97it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 66%|             | 827/1250 [00:32&lt;00:16, 26.10it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 66%|             | 830/1250 [00:32&lt;00:16, 26.20it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 67%|             | 833/1250 [00:33&lt;00:15, 26.34it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 67%|             | 836/1250 [00:33&lt;00:15, 26.24it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 67%|             | 839/1250 [00:33&lt;00:15, 26.99it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 67%|             | 842/1250 [00:33&lt;00:15, 26.83it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 68%|             | 845/1250 [00:33&lt;00:14, 27.02it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 68%|            | 848/1250 [00:33&lt;00:14, 26.89it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 68%|            | 851/1250 [00:33&lt;00:14, 26.98it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 68%|            | 854/1250 [00:33&lt;00:15, 26.17it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 69%|            | 857/1250 [00:33&lt;00:15, 25.83it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 69%|            | 860/1250 [00:34&lt;00:15, 25.93it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 69%|            | 863/1250 [00:34&lt;00:15, 25.21it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 69%|            | 866/1250 [00:34&lt;00:14, 25.85it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 70%|            | 869/1250 [00:34&lt;00:14, 26.08it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 70%|            | 872/1250 [00:34&lt;00:14, 25.49it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 70%|            | 875/1250 [00:34&lt;00:14, 25.72it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 70%|            | 878/1250 [00:34&lt;00:14, 26.20it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 70%|           | 881/1250 [00:34&lt;00:14, 25.70it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 71%|           | 884/1250 [00:35&lt;00:14, 25.67it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 71%|           | 887/1250 [00:35&lt;00:14, 25.82it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 71%|           | 890/1250 [00:35&lt;00:14, 25.67it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 71%|           | 893/1250 [00:35&lt;00:14, 25.44it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 72%|           | 896/1250 [00:35&lt;00:13, 25.55it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 72%|           | 899/1250 [00:35&lt;00:13, 25.92it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 72%|           | 902/1250 [00:35&lt;00:13, 26.18it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 72%|           | 905/1250 [00:35&lt;00:13, 26.15it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 73%|           | 908/1250 [00:35&lt;00:13, 25.66it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 73%|          | 911/1250 [00:36&lt;00:13, 25.74it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 73%|          | 914/1250 [00:36&lt;00:12, 26.09it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 73%|          | 917/1250 [00:36&lt;00:12, 25.93it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 74%|          | 920/1250 [00:36&lt;00:12, 26.32it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 74%|          | 923/1250 [00:36&lt;00:12, 25.91it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 74%|          | 926/1250 [00:36&lt;00:12, 25.95it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 74%|          | 929/1250 [00:36&lt;00:12, 25.93it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 75%|          | 932/1250 [00:36&lt;00:12, 26.13it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 75%|          | 935/1250 [00:36&lt;00:11, 26.37it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 75%|          | 938/1250 [00:37&lt;00:11, 26.40it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 75%|          | 941/1250 [00:37&lt;00:11, 26.68it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 76%|         | 944/1250 [00:37&lt;00:11, 26.83it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 76%|         | 947/1250 [00:37&lt;00:11, 26.88it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 76%|         | 950/1250 [00:37&lt;00:11, 26.26it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 76%|         | 953/1250 [00:37&lt;00:11, 26.59it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 76%|         | 956/1250 [00:37&lt;00:11, 25.97it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 77%|         | 959/1250 [00:37&lt;00:11, 26.42it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 77%|         | 962/1250 [00:38&lt;00:10, 26.20it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 77%|         | 965/1250 [00:38&lt;00:10, 26.58it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 77%|         | 968/1250 [00:38&lt;00:10, 26.55it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 78%|         | 971/1250 [00:38&lt;00:10, 26.73it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 78%|        | 974/1250 [00:38&lt;00:10, 26.22it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 78%|        | 977/1250 [00:38&lt;00:10, 26.15it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 78%|        | 980/1250 [00:38&lt;00:10, 26.46it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 79%|        | 983/1250 [00:38&lt;00:10, 26.68it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 79%|        | 986/1250 [00:38&lt;00:10, 26.35it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 79%|        | 989/1250 [00:39&lt;00:10, 26.01it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 79%|        | 992/1250 [00:39&lt;00:09, 25.92it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 80%|        | 995/1250 [00:39&lt;00:09, 26.02it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 80%|        | 998/1250 [00:39&lt;00:09, 26.23it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 80%|       | 1001/1250 [00:39&lt;00:09, 25.98it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 80%|       | 1004/1250 [00:39&lt;00:09, 25.87it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 81%|       | 1007/1250 [00:39&lt;00:09, 26.13it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 81%|       | 1010/1250 [00:39&lt;00:09, 26.12it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 81%|       | 1013/1250 [00:39&lt;00:09, 26.24it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 81%|       | 1016/1250 [00:40&lt;00:09, 24.80it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 82%|       | 1019/1250 [00:40&lt;00:09, 24.35it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 82%|       | 1022/1250 [00:40&lt;00:09, 25.12it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 82%|       | 1025/1250 [00:40&lt;00:09, 24.97it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 82%|       | 1028/1250 [00:40&lt;00:08, 25.26it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 82%|      | 1031/1250 [00:40&lt;00:08, 25.29it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 83%|      | 1034/1250 [00:40&lt;00:08, 25.23it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 83%|      | 1037/1250 [00:40&lt;00:08, 24.98it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 83%|      | 1040/1250 [00:41&lt;00:08, 25.21it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 83%|      | 1043/1250 [00:41&lt;00:08, 25.54it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 84%|      | 1046/1250 [00:41&lt;00:07, 25.74it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 84%|      | 1049/1250 [00:41&lt;00:07, 26.24it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 84%|      | 1052/1250 [00:41&lt;00:07, 26.31it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 84%|      | 1055/1250 [00:41&lt;00:07, 26.09it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 85%|      | 1058/1250 [00:41&lt;00:07, 26.16it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 85%|      | 1061/1250 [00:41&lt;00:07, 26.43it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 85%|     | 1064/1250 [00:41&lt;00:06, 26.81it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 85%|     | 1067/1250 [00:42&lt;00:06, 26.85it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 86%|     | 1070/1250 [00:42&lt;00:06, 26.78it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 86%|     | 1073/1250 [00:42&lt;00:06, 26.64it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 86%|     | 1076/1250 [00:42&lt;00:06, 27.11it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 86%|     | 1079/1250 [00:42&lt;00:06, 26.56it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 87%|     | 1082/1250 [00:42&lt;00:06, 26.97it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 87%|     | 1085/1250 [00:42&lt;00:06, 26.95it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 87%|     | 1088/1250 [00:42&lt;00:05, 27.03it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 87%|     | 1091/1250 [00:42&lt;00:06, 26.29it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 88%|    | 1094/1250 [00:43&lt;00:05, 26.34it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 88%|    | 1097/1250 [00:43&lt;00:05, 26.55it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 88%|    | 1100/1250 [00:43&lt;00:05, 26.43it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 88%|    | 1103/1250 [00:43&lt;00:05, 26.54it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 88%|    | 1106/1250 [00:43&lt;00:05, 26.01it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 89%|    | 1109/1250 [00:43&lt;00:05, 25.46it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 89%|    | 1112/1250 [00:43&lt;00:05, 24.66it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 89%|    | 1115/1250 [00:43&lt;00:05, 24.10it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 89%|    | 1118/1250 [00:44&lt;00:05, 22.53it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 90%|    | 1121/1250 [00:44&lt;00:05, 22.91it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 90%|    | 1124/1250 [00:44&lt;00:05, 23.99it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 90%|   | 1127/1250 [00:44&lt;00:04, 24.65it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 90%|   | 1130/1250 [00:44&lt;00:04, 25.33it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 91%|   | 1133/1250 [00:44&lt;00:04, 25.77it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 91%|   | 1136/1250 [00:44&lt;00:04, 25.85it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 91%|   | 1139/1250 [00:44&lt;00:04, 25.32it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 91%|   | 1142/1250 [00:45&lt;00:04, 25.60it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 92%|   | 1145/1250 [00:45&lt;00:04, 25.91it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 92%|   | 1148/1250 [00:45&lt;00:03, 25.97it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 92%|   | 1151/1250 [00:45&lt;00:03, 26.15it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 92%|   | 1154/1250 [00:45&lt;00:03, 26.27it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 93%|   | 1157/1250 [00:45&lt;00:03, 26.33it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 93%|  | 1160/1250 [00:45&lt;00:03, 26.71it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 93%|  | 1163/1250 [00:45&lt;00:03, 26.60it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 93%|  | 1166/1250 [00:45&lt;00:03, 26.64it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 94%|  | 1169/1250 [00:46&lt;00:03, 26.02it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 94%|  | 1172/1250 [00:46&lt;00:02, 26.40it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 94%|  | 1175/1250 [00:46&lt;00:02, 26.40it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 94%|  | 1178/1250 [00:46&lt;00:02, 26.66it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 94%|  | 1181/1250 [00:46&lt;00:02, 26.64it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 95%|  | 1184/1250 [00:46&lt;00:02, 26.44it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 95%|  | 1187/1250 [00:46&lt;00:02, 26.66it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 95%| | 1190/1250 [00:46&lt;00:02, 26.69it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 95%| | 1193/1250 [00:46&lt;00:02, 26.38it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 96%| | 1196/1250 [00:47&lt;00:02, 26.08it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 96%| | 1199/1250 [00:47&lt;00:01, 25.62it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 96%| | 1202/1250 [00:47&lt;00:01, 26.09it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 96%| | 1205/1250 [00:47&lt;00:01, 26.35it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 97%| | 1208/1250 [00:47&lt;00:01, 26.10it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 97%| | 1211/1250 [00:47&lt;00:01, 25.87it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 97%| | 1214/1250 [00:47&lt;00:01, 25.98it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 97%| | 1217/1250 [00:47&lt;00:01, 25.70it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 98%| | 1220/1250 [00:47&lt;00:01, 25.36it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 98%|| 1223/1250 [00:48&lt;00:01, 24.61it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 98%|| 1226/1250 [00:48&lt;00:00, 24.93it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 98%|| 1229/1250 [00:48&lt;00:00, 25.04it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 99%|| 1232/1250 [00:48&lt;00:00, 25.70it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 99%|| 1235/1250 [00:48&lt;00:00, 25.51it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 99%|| 1238/1250 [00:48&lt;00:00, 25.78it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
 99%|| 1241/1250 [00:48&lt;00:00, 25.64it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
100%|| 1244/1250 [00:48&lt;00:00, 25.75it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
100%|| 1247/1250 [00:49&lt;00:00, 25.96it/s]code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
code/__torch__/torchvision/transforms/functional.py:188: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
100%|| 1250/1250 [00:49&lt;00:00, 25.43it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracy: 0.7512
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>README.md               install_requirements.sh  reverse_requirements.txt
app.ipynb               <span class="ansi-blue-intense-fg ansi-bold">landmark_images</span>/         <span class="ansi-blue-intense-fg ansi-bold">src</span>/
<span class="ansi-blue-intense-fg ansi-bold">checkpoints</span>/            mean_and_std.pt          <span class="ansi-blue-intense-fg ansi-bold">static_images</span>/
cnn_from_scratch.ipynb  requirements.txt         transfer_learning.ipynb
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls checkpoints/
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>model_transfer.pt  transfer_exported.pt
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">shutil</span>
<span class="k">if</span> <span class="n">TRAINING_PLATFORM</span> <span class="o">==</span> <span class="s2">&quot;KAGGLE&quot;</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">kaggle</span>

    <span class="c1"># Chemin du dossier  archiver</span>
    <span class="n">source_dir</span> <span class="o">=</span> <span class="s1">&#39;/kaggle/working/checkpoints&#39;</span>
    <span class="n">zip_file</span> <span class="o">=</span> <span class="s1">&#39;/kaggle/working/dataset.zip&#39;</span>

    <span class="c1"># Crer l&#39;archive ZIP</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">make_archive</span><span class="p">(</span><span class="s1">&#39;/kaggle/working/dataset&#39;</span><span class="p">,</span> <span class="s1">&#39;zip&#39;</span><span class="p">,</span> <span class="n">source_dir</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Le fichier dataset.zip a t cr  l&#39;emplacement &#39;/kaggle/working/&#39;&#39;.&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Le fichier dataset.zip a t cr  l&#39;emplacement &#39;/kaggle/working/&#39;&#39;.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>README.md               dataset.zip              reverse_requirements.txt
app.ipynb               install_requirements.sh  <span class="ansi-blue-intense-fg ansi-bold">src</span>/
<span class="ansi-blue-intense-fg ansi-bold">checkpoints</span>/            <span class="ansi-blue-intense-fg ansi-bold">landmark_images</span>/         <span class="ansi-blue-intense-fg ansi-bold">static_images</span>/
cnn_from_scratch.ipynb  mean_and_std.pt          transfer_learning.ipynb
dataset-metadata.json   requirements.txt
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
